---
title: Asynchronism
tags: [SystemDesign, Asynchronous, Scalability, Performance, Microservices]
---

# â³ Asynchronism

## ğŸ§  Core Idea

**Asynchronism** in system design refers to executing tasks **outside the main request-response flow**.

> Goal: **Reduce request latency, improve throughput, and handle long-running tasks efficiently.**

Instead of making users wait for expensive operations, systems process them **in the background**.

---

## ğŸ“– Definition

In synchronous processing:

```
Client â†’ Request â†’ Server â†’ Process Everything â†’ Response
```

In asynchronous processing:

```
Client â†’ Request â†’ Server â†’ Immediate Response
                   â†“
            Background Processing
```

This keeps user-facing services fast and responsive.

---

## ğŸ¯ Why Asynchronism Matters

- Reduces request/response time  
- Improves user experience  
- Enables background computation  
- Helps handle high traffic loads  
- Prevents system overload  

---

## âš™ï¸ Common Asynchronous Patterns

### ğŸ”¹ Background Jobs
- Time-consuming tasks run separately  
- Example: Report generation, data aggregation  

### ğŸ”¹ Message Queues
- Services communicate via queues  
- Example: RabbitMQ, Kafka, Redis Streams  

### ğŸ”¹ Task Queues
- Specialized queues for distributing jobs  
- Example: Celery, Sidekiq  

### ğŸ”¹ Event-Driven Processing
- Services react to emitted events  
- Example: Order placed â†’ Trigger email service  

---

## ğŸš€ Common Use Cases

- Sending emails or notifications  
- Video or image processing  
- Payment processing  
- Log aggregation  
- Analytics pipelines  

---

## âš–ï¸ Message Queue vs Task Queue

| Aspect | Message Queue | Task Queue |
|--------|---------------|------------|
| Purpose | Pass messages between services | Distribute jobs to workers |
| Example Tools | Kafka, RabbitMQ | Celery, Sidekiq |
| Execution | Consumer decides action | Worker executes assigned job |
| Usage | Service communication | Background job processing |

---

## ğŸ§  Back Pressure Concept

If producers send messages faster than consumers can process:

- Queues grow  
- Memory pressure increases  
- System may crash  

**Back pressure** mechanisms slow producers when the system is overloaded.

---

## ğŸ“ Littleâ€™s Law Insight

```
L = Î» Ã— W
```
Where:
- **L** = Number of items in system  
- **Î»** = Arrival rate  
- **W** = Processing time  

Reducing **W** (via async processing) reduces system load.

---

## âš ï¸ Challenges

- Debugging complexity  
- Eventual consistency  
- Ordering guarantees  
- Monitoring async pipelines  

---

## ğŸ§  Design Insight

```
User-facing latency sensitive tasks â†’ Async
Long-running computations â†’ Background Jobs
Service communication â†’ Message Queues
```

---

## ğŸ”— Related Topics

[[Background Jobs]]  
[[Event Driven]]  
[[Schedule Driven]]  
[[Returning Results]]  
[[Microservices]]  
[[Scalability]]

---

## ğŸ“š Sources

- Patterns for Microservices  
  https://medium.com/inspiredbrilliance/patterns-for-microservices-e57a2d71ff9e  

- Back Pressure When Overloaded  
  https://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html  

- Littleâ€™s Law  
  https://en.wikipedia.org/wiki/Little%27s_law  

- Message Queue vs Task Queue  
  https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function

---

## ğŸ·ï¸ Tags

#SystemDesign #Asynchronous #Microservices #Scalability #Performance
